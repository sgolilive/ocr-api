# OCR Language Detection API

A lightweight OCR microservice built using FastAPI, Tesseract OCR, and Pillow.
This API automatically:

* Downloads the required trained data files (first run only)
* Detects language in the image
* Selects the correct Tesseract model
* Extracts text from an image URL
* Returns OCR result via a simple GET endpoint

Perfect for small apps, browser scripts, automation tools, and internal services.

### ğŸš€ Features

* ğŸ” Auto-detect image language using langdetect
* ğŸ§  OCR extraction via Tesseract (tessdata_best)
* ğŸŒ Image download from URL
* âš¡ FastAPI high-performance API
* ğŸ— Pre-download traineddata files once to speed up runtime
* ğŸ§© Easy deploy to Render / Railway / Fly.io

### ğŸŒ API Usage

#### ğŸ“Œ GET /ocr?url=IMAGE_URL
Extracts text from a remotely hosted image.

Example Request
```
GET /ocr?url=https://example.com/sample-image.jpg
```
#### Example Response
```
{
  "image_url": "https://example.com/sample.jpg",
  "detected_language": "en",
  "tesseract_lang": "eng",
  "text": "Hello world from OCR!"
}
```

### ğŸ§  How Language Detection Works

* Download image
* Try OCR using eng+spa+fra+deu+por (fast fallback set)
* Run langdetect.detect() on extracted text
* Map detected language â†’ correct Tesseract model (e.g., "en" â†’ "eng")
* Run full OCR using the correct trained data model

### ğŸ“ Project Structure
```
.
â”œâ”€â”€ app.py             # FastAPI server
â”œâ”€â”€ ocr.py             # OCR logic (all internal functions private except process_image)
â”œâ”€â”€ tessdata/          # Auto-downloaded Tesseract traineddata files
â”œâ”€â”€ requirements.txt   # Python dependencies
â”œâ”€â”€ runtime.txt        # Optional (for Heroku / Railway)
â””â”€â”€ README.md          # Documentation
```
### ğŸ”§ Installation

#### 1. Clone the repo
* git clone https://github.com/yourusername/ocr-api.git
* cd ocr-api

#### 2. Create virtual environment
* python3 -m venv venv
* source venv/bin/activate

#### 3. Install dependencies
* pip install -r requirements.txt